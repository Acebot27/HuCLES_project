{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training BData HuCLES (Human Confidence Level Evaluation System)\n",
    "\n",
    "\n",
    "### - Classification of Confidence Level\n",
    "\n",
    "<img src=\"CLevels.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation -\n",
    "\n",
    "## 1. Getting BData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video frames as images\n",
    "# !cd ./code_scripts/\n",
    "# python vid_to_img.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After this, Crop the required portion from images and paste it in respective folders(test, train, val), then run the following scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Body dataset csv file\n",
    "# python genBData.py\n",
    "# !cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data\n",
    "Here, we load the dataset and split it into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from code_scripts import prepareFData as ppFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Training set: 1046\n",
      "Number of images in Test set: 40\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"./body/bdata/dataset.csv\"\n",
    "# noEntry = 1086\n",
    "train_data, train_labels, test_data, test_labels = ppFD.load_data(dataset_path, nEntries=1086, imgShape=(480, 480))\n",
    "\n",
    "print(\"Number of images in Training set:\", len(train_data))\n",
    "print(\"Number of images in Test set:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining and Deploying CNN for training the model\n",
    "We have built ourselves a Convolutional Neural Network which has convolutional layers armed with filters that extract features out of images.\n",
    "\n",
    "We have used Keras to deploy our neural network and also have used Dropout layers frequently since Dropout layers inhibit overfitting by randomly dropping out units from the neural network. \n",
    "\n",
    "We will use 20 percent of the training data as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model package\n",
    "from code_scripts import modelCNN as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 478, 478, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 478, 478, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 478, 478, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 478, 478, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 478, 478, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 239, 239, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 239, 239, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 239, 239, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 239, 239, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 239, 239, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 239, 239, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 239, 239, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 239, 239, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 119, 119, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 119, 119, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 119, 119, 256)     295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 119, 119, 256)     1024      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 119, 119, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 119, 119, 256)     1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 119, 119, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 119, 119, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 59, 59, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 59, 59, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 59, 59, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 59, 59, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 59, 59, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 59, 59, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 59, 59, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 59, 59, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 430592)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               220463616 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 228,466,439\n",
      "Trainable params: 228,460,807\n",
      "Non-trainable params: 5,632\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 1\n",
    "batch_size = 2\n",
    "learning_rate = 0.00001\n",
    "\n",
    "# defining model\n",
    "model = md.createCNN(learning_rate, img_ht=480, img_wd=480)\n",
    "\n",
    "# saving callbacks name\n",
    "logName = 'UP_fcnn20_ep{1}'\n",
    "\n",
    "# Callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=6, mode='auto')\n",
    "checkpointer = ModelCheckpoint('./model/upperbody/bweights_ep{epoch:03d}_val_loss{val_loss:.3f}.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tB = TensorBoard(log_dir='./logs/B000{}'.format(logName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\HuCLES_Project\\code_scripts\\modelCNN.py:104: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\HuCLES_Project\\code_scripts\\modelCNN.py:106: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 836 samples, validate on 210 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1\n",
      "836/836 [==============================] - 3852s 5s/step - loss: 7.8103 - accuracy: 0.1854 - val_loss: 2.1791 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.17909, saving model to ./model/upperbody/bweights_ep001_val_loss2.179.h5\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training(or compiling/deploying) the model\n",
    "model = md.compileCNN(model, train_data, train_labels, epochs, batch_size, lr_reducer, checkpointer, early_stopper, tB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.predictCNN(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving the trained and tested model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eeab3e3f8ed5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./model/upperbody/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'md' is not defined"
     ]
    }
   ],
   "source": [
    "DIR = './model/upperbody/'\n",
    "md.saveCNN(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating our trained model on Video/Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING:tensorflow:From T:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2020-04-23 12:43:54.102484: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2020-04-23 12:43:54.720747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce GTX 980M major: 5 minor: 2 memoryClockRate(GHz): 1.1265\n",
      "pciBusID: 0000:01:00.0\n",
      "totalMemory: 8.00GiB freeMemory: 6.71GiB\n",
      "2020-04-23 12:43:54.721261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-04-23 12:43:55.400436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-23 12:43:55.400867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-04-23 12:43:55.401112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-04-23 12:43:55.401563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6458 MB memory) -> physical GPU (device: 0, name: GeForce GTX 980M, pci bus id: 0000:01:00.0, compute capability: 5.2)\n",
      "2020-04-23 12:44:02.202355: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library cublas64_100.dll locally\n"
     ]
    }
   ],
   "source": [
    "!python evaluateVideo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Screenshot of video prediction output\n",
    "<img src=\"opss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sad image output\n",
    "<img src=\"OutputImg/sadop.jpg\">\n",
    "\n",
    "##### Angry image output\n",
    "<img src=\"OutputImg/angryop.jpg\">\n",
    "\n",
    "##### Too happy image output\n",
    "<img src=\"OutputImg/happyop.jpg\">\n",
    "\n",
    "##### Confident image output\n",
    "<img src=\"OutputImg/confiop.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
